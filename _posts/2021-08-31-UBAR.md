---
title:  "UBAR paper review"
excerpt: "UBAR: Towards Fully End-to-End Task-Oriented Dialog System with GPT-2"

categories:
  - Paper review
tags:
  - Paper review
  - NLP
  - TOD
  - Dialog system
  - Task-Oriented Dialog System

last_modified_at: 2021-05-10T08:06:00-05:00
mathjax: true
classes: wide
---
[이전 리뷰](https://momozzing.github.io/study/TOD,-DST/) -> TOD, DST 설명 

[이전 리뷰](https://momozzing.github.io/paper%20review/A-Simple-Language-Model-for-Task-Oriented-Dialogue-(SimpleTOD)/) -> simpleTOD paper review
[이전 리뷰](https://momozzing.github.io/paper%20review/SOLOIST_Building-Task-Bots-at-Scale-with-Transfer-Learning-and-Machine-Teaching/) -> Soloist paper review 

[논문 링크](https://arxiv.org/pdf/2012.03539.pdf)

## **introduction**

이전의 연구들인 SimpleTOD, Soloist 같은 GPT-2 based TOD system은 몇 가지 문제점이 있고 dialog session level 대신 dialog turn level에서 train, evaluation이 진행된다. 

1. 이러한 방법의 dialog history는 user utterance, system respone 로만 구성되며 이전 턴의 belief state 및 system act 와 같은 정보는 제외된다. 제외된 정보는 현재 턴 생성에 유용한 정보가 될 수 있다. 

2. dialog history에 있는 user utterance의 system respone 는 label 이라 할 수 있는데 이 label 사용하여 dialog session과 다른 turn과 독립적으로 dialog generation을 진행한다. (같은 대화 안에 있는 문장들은 서로 의존적일텐데 독립적으로 생성한다.)

3. 실제 대화에서 정답 시스템 응답에 액세스할 수 있다는 가정은 효과적이지 않다. 

이 문제점을 해결하고 dialog session level 에서 Task-oriented dialog를 모델링 하는  Task-oriented dialog system 인 UBAR를 제안 

UBAR는 user utterance, belief state, database result, system act, system response으로 구성된 전체 dialog session sequence(input)를 Transformer 기반의 Auto-regressive language model인 GPT2에 fine-tuning 해서 답변(output)을 얻는다.

## **Model Architecture**

### **Modeling on a Dialog Session Level**

![image](https://user-images.githubusercontent.com/60643542/131630991-fd69794c-e5a1-4f1d-b0e8-f8b749d0eebd.png)

기존의 SimpleTOD, Soloist는 dialog 안에서 전체 dialog history를 input (U,S,U,S,U,S,...,U) 으로 GPT-2에 넣어 belief state, system act , system respone를 생성하였다. 

하지만 UBAR는 dialog history를 Session level로 input(U)을 GPT-2에 넣어 Belief state, system act , system respone를 생성한다. 

UBAR도 대화가 t로 진행됨에 따라 dialog session level의  User utterance로 belief state를 생성하고 이 belief state 값을 DB에 query를 보내 query에 맞는 DB값을 찾고 

User utterance, belief state, DB result를 조건으로 System Act를 얻는다. 

그리고 User utterance, belief state, DB result, System Act으로 delexicalized Response를 얻는다. 

그러면 각각의 session level의 sequence로 공식화 할 수 있다. 

기존의 방법 - $\{U_0, R_0, U_1, R_2,..., U_{t-1}, R_{t-1},U_t \}$

UBAR 제안 방법 - $\{U_0, B_0, D_0, A_0, R_0,...,U_t, B_t, D_t, A_t, R_t\}$

UBAR는 context에서 Belief state, DB result, system Act를 통합한다. 

### **Domain-Adaptive Pre-processing**

Respone를 delexicalizing 하고 Belief state, DB result, system Act의 정보를 span으로 변환하여 dialog data를 전처리를 한다. 

모든 sequence는 구성요소(U, B, D, A, R)사이에 시작(sos_?)과 끝(eos_?)을 나타내는 special token으로 둘러싸여 있다. 

![image](https://user-images.githubusercontent.com/60643542/131649291-9194a30d-0cc6-429a-97a1-d2e5ed682c7b.png)

### **Delexicalization**

모델이 독립적인 매개변수를 학습할 수 있도록 Delexicalized response를 generation 해야한다. 

Delexicalization는 특정한 slot값을 해당되는 카테고리에 넣어두어 respose generation할 때 카테고리가 출력되게 하는 방법이다. 

ex) I like Ryon  -> I like <value_name>

이 값은 나중에 DB의 검색 결과로 채워진다. 

## DATA
![image](https://user-images.githubusercontent.com/60643542/117672582-f4a44c00-b1e4-11eb-87e8-3a74098aba62.png)

## Experiments
![image](https://user-images.githubusercontent.com/60643542/117672632-fcfc8700-b1e4-11eb-9506-f2ae16fa7562.png)

![image](https://user-images.githubusercontent.com/60643542/117672665-02f26800-b1e5-11eb-9765-e3f92cffef54.png)

![image](https://user-images.githubusercontent.com/60643542/117672691-08e84900-b1e5-11eb-9604-8fda004863c4.png)

## Conclusion
![image](https://user-images.githubusercontent.com/60643542/117672722-0e459380-b1e5-11eb-84b1-881b5fc10ada.png)