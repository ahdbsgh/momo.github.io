---
title:  "DSS-DST Paper review"
excerpt: "Dual Slot Selector via Local Reliability Verification
for Dialogue State Tracking"

categories:
  - Paper review
tags:
  - Paper review
  - NLP
  - TOD
  - Dialog system
  - DST
  - Dialog State Tracking
last_modified_at: 2021-08-27T08:06:00-05:00
mathjax: true
classes: wide
---
[논문 링크](https://arxiv.org/pdf/2107.12578.pdf)

[이전 리뷰](https://momozzing.github.io/study/TOD,-DST/) -> TOD, DST 설명 

[이전 리뷰](https://momozzing.github.io/paper%20review/TripPy/) -> TripPy paper review

[이전 리뷰](https://momozzing.github.io/paper%20review/TripPy+SaCLog/) -> TripPy + SaCLog Paper review

[현재 논문 깃헙 레포](https://github.com/guojinyu88/DSSDST)

[DST 논문들 정리 깃헙 레포](https://github.com/yukyunglee/Awesome-Dialogue-State-Tracking) -> 감사합니다
## **introduction**

현재 기준 Multi-domain DST 1위 모델 

기존의 접근방식은 일반적으로 한 Dialog안에서 처음부터 매 턴마다 Dialog state를 예측한다. 

하지만 매 턴마다 대부분의 slot은 이전 턴의 slot값을 갖고 있는것(상속)이 대부분이다. 

그래서 본 논문은 매 턴 마다 slot값을 동일하게 처리하는 메커니즘은 비효율적이고 중복된 slot값 생성에 따른 오류가 발생 한다는 문제점을 지적 

본 논문은 이러한 문제점을 해결하기 위해 현재 턴 dialog를 기반으로 하는 Dual Slot Selector와 dialog history 을 기반으로 하는 Slot Value Generator 두 단계로 구성된 DSS-DST를 제안한다. 

**Dual Slot Selector**
각 턴에서 모든 slot은 Dual Slot Selector에 의해 두 가지 측면에서 slot값을 업데이트를 할지, 이전 slot의 값을 상속받을지 결정한다.

1. slot과 현재 대화 간의 relation이 강할 경우 
2. 현재 턴 대화를 통해 신뢰도가 높은 slot값을 얻을 수 있는 경우
  
  업데이트 되도록 결정된 slot은 hybrid 방식으로 값을 업데이트 하기 위해 Slot Value Generator에 입력하여 slot값을 업데이트하며,  다른 slot들은 이전 턴의 slot값을 상속 받는다. 

Dual Slot Selector는 Preliminary Selector와 Ultimate Selector 의 두단계로 구성되며 현재 turn 대화에 따라 각 slot을 공동으로 결정한다.

Preliminary Selector는 대부분의 관련 없는 slot을 제외하기 위해 대략적으로 판단하고 
Ultimate Selector가 Preliminary Selector에서 판단된 결과를 최종적으로 판단하고 
Preliminary Selector의 결정과 합쳐서 최종 결정한다. 
Preliminary Selector는 현재턴의 dialog utturence와  slot간의 관계를 간략하게 설명한다.
그 후 Ultimate Selector가 각 슬롯에 대한 임시 slot값을 얻고 안정성은 계산
Ultimate Selector의 근거는 현재 턴 대화를 통해 높은 신뢰도의 slot값을 얻을 수 있다면 slot을 업데이트 해야 한다는 것. 

최종적으로 선택된 슬롯은 Slot Value Generator에 진입하고 추출방식, 분류기반의 방식의 하이브리드 방식을 활용해서 현재 dialog utturence및 dialog history에 따른 값을 생성한다. 

본 논문에서 제안하는 contribution은 총 3가지 이다. 

- 중복 slot값 생성을 완화시키기 위해 Current turn dialogue를 기반으로 하는 Dual Slot Selector와 dialog history를 기반으로 하는 Slot Value Generator로 구성된 DSS-DST를 고안

- slot 선택의 성능을 크게 향상시키는 두 가지 보완 조건을 판단 기준으로 제안

- 본 논문의 결과는 DST 모델중에 SOTA를 찍었다는것
  

## **Model Architecture**
![image](https://user-images.githubusercontent.com/60643542/131292599-5af34bcd-7e9e-4b5f-b99d-dd57c8ef7e08.png)

### **define**

$Dialog = \{(U_1,R_1);(U_2,R_2),...,;(U_t,R_t)\}$

$U_i$ = user utterence, $R_i$ = system response utterence $t$ = turn

dialog state at turn: $B_t$ = $ \{ (S^j , V_t^j) \mid  1 \le j \le J \} $

$S^j, V_t^j$:  $B_t$안에 있는 slot, value 각각의 값, $J$ = total number of such slots

### **Embedding**

$B_{t-1}$ = 이전 턴의 dialog state $D_t$ = 현재턴의 dialog representation
$X_t$ = input

$$X_t = [CLS] \oplus D_t \oplus B_{t-1}$$

여기서 [CLS] 토큰을 매 턴마다 앞에 넣어주는 것은 SOM-DST ([논문링크](https://arxiv.org/pdf/1911.03906.pdf)) 에서 얻어온 것

$D_t = R_t \oplus ; \oplus U_t \oplus [SEP],$

$U_t$ = user utterence, $R_t$ = system response utterence $t$ = turn

$D_t$ 사이의 ; 은 $R_T$와 $U_t$ 사이를 구분하기위한 special token 이고 [SEP]token은 대화의 끝을 알기 위한 special token이다. 

**Representation of the dialog state at turn**

$B_t = B_t^1 \oplus ... \oplus B_t^J,$ 에서 

$B_t^j = [SLOT]^j \oplus S_j \oplus - \oplus V_t^j$ 는 j번째 slot-value pair이고 - 는 Slot과 Value사이를 구분하는 Special token 이고 

$[SLOT]^j$는 j번째 slot-value pair 의 aggregation information을 나타내는 Special token이다.

이러한 $X_t$의 input을 **ALBERT**에 넣음 

**인코더의 output representation** 

$O_t \in \mathbb{R}^{\mid X_t \mid \times d}$

$[CLS]$ = $h_t^{[CLS]}$, $[SLOT]^j$ = $h_t^{[SLOT]^j}$

$h_t^{[CLS]} , h_t^{[SLOT]^j} \in \mathbb R^d$

turn t와 turn t-1의 dialog state의 representation을 얻기 위해 $O_t$를 $H_t, H_{t-1}^B$로 분할 

### **Dual Slot Selector**
Dual Slot Selector는 Preliminary Selector와 Ultimate Selector로 구성되며 현재 턴 대화에 따라 각 slot을 공동으로 판단한다.

**Slot-Aware Matching(SAM)**

slot은 Question의 범주가 될 수 있다. MRC 이전의 연구에서 구절과 질문 사이의 명시적인 Attention 사용한 Idea를 채용 

$$SAM(H,j,t) = \mathbf {softmax}(H(h_t^{[SLOT]^j})^T)$$

$H$ = 현재 턴 representation, $h_t^{[SLOT]^j}$ = 현재턴 SLOT representation

$H$에 대한 Attention 수행을 $h_t^{[SLOT]^j}$로 취함

SAM의 output은 턴 t에서 H의 각 위치와 j번째 SLOT 간의 correlation 를 나타낸다.

**Preliminary Selector**

현재 턴 dialog utterence와  각 SLOT의 correlation을 보고 1차 판단을 내린다. 

턴 t에서 j번째 SLOT(1 ≤ j ≤ J)에 대해 출력 표현 $h_t^{[SLOT]^j}$와 dialog representation인 $H_t$를 SAM에 공급한다.

$$\alpha_{t}^j = SAM(H_t,j,t)$$

여기서 $\alpha_t^j \in \mathbb R^{N \times 1}$은 dialog의 각 위치와 턴 T에서 J번째 슬롯간의 correlation을 나타냄 그 후 aggregate된 dialog representation인 $H_t^j \in \mathbb R^{N \times d}$ 값을 얻고 이를 Fully connected layer로 보내 
j 번째 SLOT의 logit $\hat{y}_t^j$가 $\mathbf {logit \ sel}_t^i$와 $\mathbf {logit \ fai}_t^j$ 두 가지로 classification이 된다. 

$$H_t^j,_m = \alpha_{t}^j,_m H_{t,m}, 0 \le m < N $$
$$\hat{y}_t^j = \mathbf{softmax}(FC(H+t^j))$$

턴 t에서 j번째 slot에 대한 $Pre \ score_t^j =  \mathbf {logit \ sel}_t^i - \mathbf {logit \ fai}_t^j$를 계산한다. 

slot index의 집합을 $U_{1,t} = {\{j \mid Pre \ score_t^j > 0\}}$ 로 정의 
slot size는 $J_{1,t} = \mid U_{1,t} \mid $

그 후  U_{1,t} 는 Ultimate Selector의 input이 됨

**Ultimate Selector**

Ultimate Selector는 Preliminary Selector가 각 SLOT의 correlation을 보고 내린 1차 판단을 가지고 현재 턴 T의 대화간의 신뢰성 검사를 통해 신뢰도를 계산하는 것이다. 

먼저 $U_{1,t}(1 \le j \le J_{1,t})$의 j 번째 slot에 대해 extracive method를 적용해 임시 slot값인 $\varphi_t^j$를 얻는다. 

그리고 두개의 서로 다른 linear layer를 사용하고 $H_t$를 입력으로 공급해서 각각 시작과 끝을 예측하기 위한 representation인 $H_{s_t}$와 $H_{e_t}$를 얻는다 그 후
Correlation representation인 $\alpha \ {s_t^j}$, $\alpha \ {e_t^j}$ 얻기 위해 
j 번쨰 slot이 있는 SAM에 넣는다 

![image](https://user-images.githubusercontent.com/60643542/131324786-9a7c63d8-6d7f-4fbf-b8ee-6d3022c1b73f.png)

$\alpha \ {s_t^j}$, $\alpha \ {e_t^j}$에서 최대값의 위치는 $\varphi_t^j$의 시작과 끝 예측이 된다. 

![image](https://user-images.githubusercontent.com/60643542/131325087-79f9d809-b515-489c-b65f-b3411b0ef652.png)

이제 j번쨰 slot의 후보 값의 집합인 $\mathcal{V}_j$를 정의한다. 

$\varphi_t^j$ 가 $\mathcal{V}_j$에 속하면 extract 가능한 모든 $\varphi_t^j$(임시슬롯)값의 비율을 계산하고 j번째 slot인 $Ult \ score_t^j$의 점수를 계산한다. 

![image](https://user-images.githubusercontent.com/60643542/131325694-831075a9-b464-46cb-a560-45ad6386be42.png)

$\varphi_t^j$ 가 $\mathcal{V}_j$에 속하지 않으면 $\mathcal{V}_j$에서 임시 Slot값을 선택 하기 위해 Classification 기반의 방법을 사용

dialog representation인 $H_t^j$ 는 $\mathcal{V}_j$의 분포를 얻기 위해 Fully connected layer 연결한다. 최대값에 해당되는 후보 slot을 새로운 임시 슬롯  $\varphi_t^j$ 로 선택하고 $\varphi_t^j$와 $None$ 사이의 분포 확률 차이를 $Ult \ score_t^j$로 계산

![image](https://user-images.githubusercontent.com/60643542/131449188-2e38cf10-59ad-4b0e-af15-2b241b3e1045.png)

**Threshold-based decision**

$U_{1,t}$의 각 slot값에 대한 최종 결정을 내리기 위해 Threshold-based 방식을 사용하였다.  Threshold값인 $\delta$는 모델안에서 설정되고 결정된다(파라미터로 사용하는것 같음) 

![image](https://user-images.githubusercontent.com/60643542/131450818-bd69d53c-50ee-4da0-96dc-e180abd8cac7.png)

$\beta$ 는 weight, slot index set을 $U_{2,t}$ = ${\{j \mid Total \ score_t^j > \delta\}}$, slot index set의 size는 $J_{2,t} = \mid U_{2,t} \mid $

$U_{2,t}$의 slot은 Slot Value Generator에 들어가 slot값을 업데이트 한다. 

**Slot Value Generator**

Dual Slot Selector에 의해 $U_{2,t}$는 최종 선택된 slot값이다. $U_{2,t}$의 각 j 번째 slot에 대해 이에 대한 값을 생성한다. 

반대로 $U_{2,t}$에 없는 slot값은 이전 턴의 slot값을 상속받는다. 
즉 $V_t^i = V_{t-1}^i, 1 \le i \le J - J_{2,t}$

Slot Value Generator은 Ultimate Selector와 동일한 추출방법과 분류 기반의 방식을 사용한다. 그래서 아래와 같이 추상화 하였다. 

![image](https://user-images.githubusercontent.com/60643542/131452030-11e92be7-e883-4eb3-805e-8f7790359072.png)

20번 식은 dialog history도 input단에 넣은것이다.
21번 식은 이를 임베딩해서 값을 얻는 것이고
22, 23,번 식은 추출 방법을 통해 이전 값을 상속받을지 말지 결정하는 것이고
24번 식은 분류 기반 방법을 통해 slot값 생성후에 대입하는 식이다. 

Slot Value Generator와 Ultimate Selector의 차이점은 Slot Value Generator는 이전 k-1턴 + 현재턴을 input으로 넣는데 Ultimate Selector는 현재턴만 input으로 넣는다. 

**Optimization**

Preliminary Selector는 CE로 학습 여기서 $\hat{y}_t^j$ 는 slot 예측을 나타내고 $y_t^j$ 는 slot 선택 여부를 나타낸다. 



![image](https://user-images.githubusercontent.com/60643542/131452701-5737fdc9-b6a8-4468-9392-f763e0c58d1a.png)

Ultimate Selector는 Extractive method와 Classification-based method를 사용했다. 그래서 두가지의 loss가 나온다. 이 두가지도 CE를 통해 정의된다. 
여기서 $logit \ p_t^j$는 추출 가능한 모든 임시slot값중 식 13을 통해 얻은 타겟값이고
$y \ c_{t,i}^j$는 후보 값의 확률을 나타내는 값이다. 

![image](https://user-images.githubusercontent.com/60643542/131452994-0b6f8794-7aa4-4f01-9bad-5d9cf280d902.png)

Slot Value Generator의 Loss는 Ultimate Selector의 loss와 같은 방식으로 학습된다. 

## **Experiment**

### **Data**
데이터셋은 MultiWOZ 2.2, MultiWOZ 2.1, MultiWOZ 2.0에 대해서 진행한다. 

이들은 10000개 이상의 multi-domain 발화로 구성 되어 있으며 35개의 domain-slot쌍과 5개의 도메인(기차, 레스토랑, 호텔, 택시, 명소)로 구성되어 있다. 공개적으로 사용 가능한 가장 큰 3개의 multi-domain TOD dataset이다. 
MultiWOZ 2.1는 대화 상태의 주석 오류를 식별 및 수정하고 상태 업데이트의 불일치 및 온톨로지의 문제를 해결하고 모든 슬롯을 비범주 및 범주의 두 가지 유형으로 나누어 데이터 세트를 재정의하였다. 

### **Evaluation**
joint goal accuracy (JGA)로 평가 진행

### **Baseline Models**

[DSTreader](https://arxiv.org/pdf/1908.01946.pdf)는 DST의 문제를 extractive QA 작업으로 공식화하고 input에서 slot 값을 범위로 추출한다(Gao et al., 2019). 

[TRADE](https://arxiv.org/pdf/1905.08743.pdf)는 전체 대화 컨텍스트를 인코딩하고 copy augmented 디코더를 사용하여 모든 slot의 값을 디코딩한다(Wu et al., 2019). 

[NADST](https://arxiv.org/pdf/2002.08024.pdf)는 Transformer 기반의 non-autoregressive 디코더를 사용하여 current turn dialogue state를 생성한다(Le et al., 2019). 

[PIN](https://arxiv.org/pdf/2009.07616.pdf)은 in-turn dependencies 과 crossturn dependencies 을 jointly model을 위해 interactive 인코더를 통합한다.(Chen et al., 2020a). 

[DS-DST](https://arxiv.org/pdf/1910.03544.pdf)는 두 개의 BERT 기반 인코더를 사용하고 hybrid 접근 방식을 취한다.(Zhang et al., 2020a). 

[SAS](https://aclanthology.org/2020.acl-main.567.pdf)는 중복된 정보의 간섭을 줄이기 위해 Slot Attention 및  Slot Information Sharing 이 있는 Dialogue State Tracker를 제안한다.(Hu et al., 2020). 

[SOM-DST](https://arxiv.org/pdf/1911.03906.pdf)는  dialogue state 를 explicit fixedsize memory (명시적 고정 크기 메모리)로 간주하고 selectively overwriting mechanism 을 제안한다(Kim et al., 2020). 

[DST-Picklist](https://arxiv.org/pdf/1910.03544.pdf)는 모든 slot 을 picklist-based slots으로  간주하여 후보 값과 slot-context encoding 간의 일치를 수행한다(Zhang et al., 2020a). 

[SST](https://ojs.aaai.org/index.php/AAAI/article/view/6250)는 Graph Attention Network 가 있는 schema-based Multi-domain Dialog State Tracker를 제안한다(Chen et al., 2020b). 

[TripPy](https://momozzing.github.io/paper%20review/TripPy/)는 three copy mechanisms에 의해 dialog context에서 모든 값을 추출한다(Heck et al., 2020).

### **Result**

baseline들과의 비교 실험 결과 

![image](https://user-images.githubusercontent.com/60643542/131458041-fc7c998e-fc9b-400d-bc6b-02b1e6d0a10e.png)

Pre-Train LM encorder부분 바꿔서 실험한 결과 

![image](https://user-images.githubusercontent.com/60643542/131458241-720c426c-332f-4dee-8912-657e64e1dfee.png)

기존 모델에서 Ultimate Selector, Preliminary Selector, 두개 다 뺸거 실험 결과 

![image](https://user-images.githubusercontent.com/60643542/131464511-1cc52dfa-01e8-4d34-96b9-3328738f1b4f.png)


dialog history 얼마나 사용 하는지에 따른 실험 결과

![image](https://user-images.githubusercontent.com/60643542/131464734-de06a8b4-40f6-4758-9e49-e597abe21aad.png)

## **Conclusion**

현재 기준 Multi-domain DST 1위 모델 

기존의 접근방식은 일반적으로 한 Dialog안에서 처음부터 매 턴마다 Dialog state를 예측한다. 

하지만 매 턴마다 대부분의 slot은 이전 턴의 slot값을 갖고 있는것(상속)이 대부분이다. 

그래서 본 논문은 매 턴 마다 slot값을 동일하게 처리하는 메커니즘은 비효율적이고 중복된 slot값 생성에 따른 오류가 발생 한다는 문제점을 지적 

본 논문은 이러한 문제점을 해결하기 위해 현재 턴 dialog를 기반으로 하는 Dual Slot Selector와 dialog history 을 기반으로 하는 Slot Value Generator 두 단계로 구성된 DSS-DST를 제안한다. 

본 논문에서 제안한 방법론들은 다 좋은 성능 향상이 있었으며 

MultiWOZ2.0, MultiWOZ2.1, MultiWOZ2.2에서 모두 sota를 찍은 논문이다. 