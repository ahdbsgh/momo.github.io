---
title:  "DSS-DST Paper review"
excerpt: "Dual Slot Selector via Local Reliability Verification
for Dialogue State Tracking"

categories:
  - Paper review
tags:
  - Paper review
  - NLP
  - TOD
  - Dialog system
  - DST
  - Dialog State Tracking
last_modified_at: 2021-08-27T08:06:00-05:00
mathjax: true
classes: wide
---
[논문 링크](https://arxiv.org/pdf/2107.12578.pdf)

[이전 리뷰](https://momozzing.github.io/study/TOD,-DST/) -> TOD, DST 설명 

[이전 리뷰](https://momozzing.github.io/paper%20review/TripPy/) -> TripPy paper review

[이전 리뷰](https://momozzing.github.io/paper%20review/TripPy+SaCLog/) -> TripPy + SaCLog Paper review

[현재 논문 깃헙 레포](https://github.com/guojinyu88/DSSDST)

[DST 논문들 정리 깃헙 레포](https://github.com/yukyunglee/Awesome-Dialogue-State-Tracking) -> 감사합니다
## **introduction**

현재 기준 Multi-domain DST 1위 모델 

기존의 접근방식은 일반적으로 한 Dialog안에서 처음부터 매 턴마다 Dialog state를 예측한다. 

하지만 매 턴마다 대부분의 slot은 이전 턴의 slot값을 갖고 있는것(상속)이 대부분이다. 

그래서 본 논문은 매 턴 마다 slot값을 동일하게 처리하는 메커니즘은 비효율적이고 중복된 slot값 생성에 따른 오류가 발생 한다는 문제점을 지적 

본 논문은 이러한 문제점을 해결하기 위해 현재 턴 dialog를 기반으로 하는 Dual Slot Selector와 dialog history 을 기반으로 하는 Slot Value Generator 두 단계로 구성된 DSS-DST를 제안한다. 

**Dual Slot Selector**
각 턴에서 모든 slot은 Dual Slot Selector에 의해 두 가지 측면에서 slot값을 업데이트를 할지, 이전 slot의 값을 상속받을지 결정한다.

1. slot과 현재 대화 간의 relation이 강할 경우 
2. 현재 턴 대화를 통해 신뢰도가 높은 slot값을 얻을 수 있는 경우
  
  업데이트 되도록 결정된 slot은 hybrid 방식으로 값을 업데이트 하기 위해 Slot Value Generator에 입력하여 slot값을 업데이트하며,  다른 slot들은 이전 턴의 slot값을 상속 받는다. 

Dual Slot Selector는 Preliminary Selector와 Ultimate Selector 의 두단계로 구성되며 현재 turn 대화에 따라 각 slot을 공동으로 결정한다.

Preliminary Selector는 대부분의 관련 없는 slot을 제외하기 위해 대략적으로 판단하고 
Ultimate Selector가 Preliminary Selector에서 판단된 결과를 최종적으로 판단하고 
Preliminary Selector의 결정과 합쳐서 최종 결정한다. 
Preliminary Selector는 현재턴의 dialog utturence와  slot간의 관계를 간략하게 설명한다.
그 후 Ultimate Selector가 각 슬롯에 대한 임시 slot값을 얻고 안정성은 계산
Ultimate Selector의 근거는 현재 턴 대화를 통해 높은 신뢰도의 slot값을 얻을 수 있다면 slot을 업데이트 해야 한다는 것. 

최종적으로 선택된 슬롯은 Slot Value Generator에 진입하고 추출방식, 분류기반의 방식의 하이브리드 방식을 활용해서 현재 dialog utturence및 dialog history에 따른 값을 생성한다. 

본 논문에서 제안하는 contribution은 총 3가지 이다. 

- 중복 slot값 생성을 완화시키기 위해 Current turn dialogue를 기반으로 하는 Dual Slot Selector와 dialog history를 기반으로 하는 Slot Value Generator로 구성된 DSS-DST를 고안

- slot 선택의 성능을 크게 향상시키는 두 가지 보완 조건을 판단 기준으로 제안

- 본 논문의 결과는 DST 모델중에 SOTA를 찍었다는것
  

## **Model Architecture**
![image](https://user-images.githubusercontent.com/60643542/131292599-5af34bcd-7e9e-4b5f-b99d-dd57c8ef7e08.png)

### **define**

$Dialog = \{(U_1,R_1);(U_2,R_2),...,;(U_t,R_t)\}$

$U_i$ = user utterence, $R_i$ = system response utterence $t$ = turn

dialog state at turn : $B_t = \{(S^j,V_t^j)|1 \le j \le J\}$

$S^j, V_t^j$:  $B_t$안에 있는 slot, value 각각의 값, $J$ = total number of such slots

### **Embedding**

$B_{t-1}$ = 이전 턴의 dialog state $D_t$ = 현재턴의 dialog representation
$X_t$ = input

$$X_t = [CLS] \oplus D_t \oplus B_{t-1}$$

여기서 [CLS] 토큰을 매 턴마다 앞에 넣어주는 것은 SOM-DST ([논문링크](https://arxiv.org/pdf/1911.03906.pdf)) 에서 얻어온 것

$D_t = R_t \oplus ; \oplus U_t \oplus [SEP],$

$U_t$ = user utterence, $R_t$ = system response utterence $t$ = turn

$D_t$ 사이의 ; 은 $R_T$와 $U_t$ 사이를 구분하기위한 special token 이고 [SEP]token은 대화의 끝을 알기 위한 special token이다. 

**Representation of the dialog state at turn**

$B_t = B_t^1 \oplus ... \oplus B_t^J,$ 에서 

$B_t^j = [SLOT]^j \oplus S_j \oplus - \oplus V_t^j$ 는 j번째 slot-value pair이고 - 는 Slot과 Value사이를 구분하는 Special token 이고 

$[SLOT]^j$는 j번째 slot-value pair 의 aggregation information을 나타내는 Special token이다.

이러한 $X_t$의 input을 **ALBERT**에 넣음 

**인코더의 output representation** 

$O_t \in \mathbb R^{|X_t| \times d}$

$[CLS]$ = $h_t^{[CLS]}$, $[SLOT]^j$ = $h_t^{[SLOT]^j}$

$h_t^{[CLS]} , h_t^{[SLOT]^j} \in \mathbb R^d$

turn t와 turn t-1의 dialog state의 representation을 얻기 위해 $O_t$를 $H_t, H_{t-1}^B$로 분할 

### **Dual Slot Selector**
Dual Slot Selector는 Preliminary Selector와 Ultimate Selector로 구성되며 현재 턴 대화에 따라 각 slot을 공동으로 판단한다.

**Slot-Aware Matching(SAM)**

slot은 Question의 범주가 될 수 있다. MRC 이전의 연구에서 구절과 질문 사이의 명시적인 Attention 사용한 Idea를 채용 

$$SAM(H,j,t) = \mathbf {softmax}(H(h_t^{[SLOT]^j})^T)$$

$H$ = 현재 턴 representation, $h_t^{[SLOT]^j}$ = 현재턴 SLOT representation

$H$에 대한 Attention 수행을 $h_t^{[SLOT]^j}$로 취함

SAM의 output은 턴 t에서 H의 각 위치와 j번째 SLOT 간의 correlation 를 나타낸다.

**Preliminary Selector**

현재 턴 dialog utterence와  각 SLOT의 correlation을 보고 1차 판단을 내린다. 

턴 t에서 j번째 SLOT(1 ≤ j ≤ J)에 대해 출력 표현 $h_t^{[SLOT]^j}$와 dialog representation인 $H_t$를 SAM에 공급한다.

$$\alpha_{t}^j = SAM(H_t,j,t)$$

여기서 $\alpha_t^j \in \mathbb R^{N \times 1}$은 dialog의 각 위치와 턴 T에서 J번째 슬롯간의 correlation을 나타냄 그 후 aggregate된 dialog representation인 $H_t^j \in \mathbb R^{N \times d}$ 값을 얻고 이를 Fully connected layer로 보내 
j 번째 SLOT의 logit $\hat{y}_t^j$가 $\mathbf {logit \_ sel}_t^i$와 $\mathbf {logit \_ fai}_t^j$ 두 가지로 classification이 된다. 

$$H_t^j,_m = \alpha_{t}^j,_m H_{t,m}, 0 \le m < N $$
$$\hat{y}_t^j = \mathbf{softmax}(FC(H+t^j))$$

턴 t에서 j번째 slot에 대한 $Pre \_ score_t^j =  \mathbf {logit \_ sel}_t^i - \mathbf {logit \_ fai}_t^j$를 계산한다. 

slot index의 집합을 $U_{1,t} = {\{j|Pre \_ score_t^j > 0}\}$ 로 정의 
slot size는 $J_{1,t} = |U_{1,t}|$

그 후  U_{1,t} 는 Ultimate Selector의 input이 됨

**Ultimate Selector**

Ultimate Selector는 Preliminary Selector가 각 SLOT의 correlation을 보고 내린 1차 판단을 가지고 현재 턴 T의 대화간의 신뢰성 검사를 통해 신뢰도를 계산하는 것이다. 

먼저 $U_{1,t}(1 \le j \le J_{1,t})$의 j 번째 slot에 대해 extracive method를 적용해 임시 slot값인 $\varphi_t^j$를 얻는다. 

그리고 두개의 서로 다른 linear layer를 사용하고 $H_t$를 입력으로 공급해서 각각 시작과 끝을 예측하기 위한 representation인 $H_{s_t}$와 $H_{e_t}$를 얻는다 그 후
Correlation representation인 $\alpha\_{s_t^j}$, $\alpha\_{e_t^j}$ 얻기 위해 
j 번쨰 slot이 있는 SAM에 넣는다 

![image](https://user-images.githubusercontent.com/60643542/131324786-9a7c63d8-6d7f-4fbf-b8ee-6d3022c1b73f.png)

$\alpha\_{s_t^j}$, $\alpha\_{e_t^j}$에서 최대값의 위치는 $\varphi_t^j$의 시작과 끝 예측이 된다. 
![image](https://user-images.githubusercontent.com/60643542/131325087-79f9d809-b515-489c-b65f-b3411b0ef652.png)

이제 j번쨰 slot의 후보 값의 집합인 $\mathcal{V}_j$를 정의한다. 

$\varphi_t^j$ 가 $\mathcal{V}_j$에 속하면 extract 가능한 모든 $\varphi_t^j$값의 비율을 계산하고 j번째 slot인 $Ult\_score_t^j$의 점수를 계산한다. 

![image](https://user-images.githubusercontent.com/60643542/131325694-831075a9-b464-46cb-a560-45ad6386be42.png)

$\varphi_t^j$ 가 $\mathcal{V}_j$에 속하지 않으면 $\mathcal{V}_j$

## **Experiment**

실험은 Transformer-based인 TripPy 모델과 RNN-based인 TRADE 모델에 SaCLog를 적용하여 실험하였다.  
### **Data**
데이터셋은 MultiWOZ 2.1, WOZ 2.0에 대해서 진행한다. 

MultiWOZ2.1은 10000개 이상의 multi-domain 발화로 구성 되어 있으며 30개의 domain-slot쌍과 5개의 도메인(기차, 레스토랑, 호텔, 택시, 명소)로 구성되어 있다. 
WOZ 2.0은 단일 도메인 데이터셋들이며 MultiWOZ2.1 보다 훨씬 작은데이터다.

### **Evaluation**
joint goal accuracy (JGA)로 평가 진행

### **Result**
TripPy + SaCLog

![image](https://user-images.githubusercontent.com/60643542/131026526-a96b7367-f759-47a7-b9c8-8a63cb34d0bc.png)

TripPy + 각각의 실험 진행 

![image](https://user-images.githubusercontent.com/60643542/131026893-683a5b70-c2d3-48a0-9ed3-98fe9fb23776.png)

TRADE + SaCLog

![image](https://user-images.githubusercontent.com/60643542/131026974-e287a08d-328b-44c1-ac91-329a0d02c957.png)



## **Conclusion**

현재 기준 Multi-domain DST 2위 모델 

기존의 DST모델은 데이터셋의 구조 정보를 무시하고 Ramdom하게 데이터를 뽑아서 학습시킨다. 

본 논문은 Task-Oriented dialog system을 위해 Curriculum구조와 Schema구조를 활용 하기 위해 **S**chema-**a**ware **C**urriculum **L**earning for Dial**og** State Tracking (SaCLog) 방식을 제안

SaCLog 방식은 schema 정보로 DST 모델을 pre-train하는 **Preview module**, train data의 난이도를 easy to hard로 정리하고 Curriculum learning을 위한 **Curriculum module**, Curriculum learning의 학습을 강화시키기 위해 예측이 잘못된 데이터를 늘리는 **Review modul**, 총 3개의 module 구조를 가지고 있다. 

이 방식은 Transformer-based, RNN-based 모델에 적용시켜 DST의 성능을 개선했다. 

Trasformer-based model 은 TripPy를 사용했고 RNN-based model 은 TRADE를 사용했다. 

SaCLog방식을 두 모델에 적용했을시 기존의 두 모델의 성능보다 높은 성능을 내었다. 