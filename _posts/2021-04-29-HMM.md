# Hiddn markov models = HMM

[https://ratsgo.github.io/machine learning/2017/03/18/HMMs/](https://ratsgo.github.io/machine%20learning/2017/03/18/HMMs/) 참고하였습니다. 

HMM은 Markov chain을 전제로 한 모델 이다.

Markov chain은  Markov Property을 지닌 이산 확률과정을 가르킨다. 

Markov chain은 한 상태의 확률은 단지 그 이전상태에만 의존한다는 것이 핵심.

즉 한 상태에서 다른상태로의 transition(전이)는 여태까지 나온 Sequence를 필요로 하지않고 바로 직전상태에서의 transition으로 추정 가능하다.

![image](https://user-images.githubusercontent.com/60643542/116524274-27f7f880-a912-11eb-9177-4039df256480.png)

날씨를 Markov chain으로 모델링을 하면 

![image](https://user-images.githubusercontent.com/60643542/116524351-3e05b900-a912-11eb-81a3-7f6f7c4d3f60.png)

엣지위의 aij 는 i번째 상태에서 j번째 상태로 전이할 확률이다.

각 노드별로 전이확률의 합은 1 이다. 

상태를 나타내는 cold hot warm 외에도 start,end state도 있다. 

HMM은 각 상태가 Markov chain을 따르는데 은닉(Hidden)되있다고 가정.

관측치 뒤에 은닉되어 있는 state를 추정하고자 하는것. 

### Forward Algorithm 
→ likelihood 를 최대화 하는 방법으로 학습 진행   
→ 하지만 연산량이 매우 많아짐 → dynamic programming 기법을 사용

dynamic programming → 중복되는 계산을 저장했다가 푸는 원리.

### Decoding Algorithm 
→ Vitervi Algorithm
→ 모델에 관측치 시퀀스O가 주어졌을때 가장 확률이 높은 은닉상태의 시퀀스Q를 찾는것.

### Training
-> EM Algorithm 으로 maximum likelihood를 찾는 방식으로 학습.